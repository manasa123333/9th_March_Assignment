{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4173a7b1-efc4-4cb5-95d9-42fec6978273",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c884e-9285-43c7-98e5-4822c39e7e8f",
   "metadata": {},
   "source": [
    "Probability Mass Function Definition                                                      \n",
    "Probability mass function can be defined as the probability that a discrete random variable will be exactly equal to some particular value. In other words, the probability mass function assigns a particular probability to every possible value of a discrete random variable.                                               \n",
    "\n",
    "Probability Mass Function Example                                                   \n",
    "Suppose a fair coin is tossed twice and the sample space is recorded as S = [HH, HT, TH, TT]. The probability of getting heads needs to be determined. Let X be the random variable that shows how many heads are obtained. X can take on the values 0, 1, 2. The probability that X will be equal to 1 is 0.5. Thus, it can be said that the probability mass function of X evaluated at 1 will be 0.5.                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0232a-bb84-45c0-941e-f92a03b30aef",
   "metadata": {},
   "source": [
    "Probability Density Function Definition                                                     \n",
    "Probability density function defines the density of the probability that a continuous random variable will lie within a particular range of values. To determine this probability, we integrate the probability density function between two specified points.                                                 \n",
    "\n",
    "Probability Density Function Example                                               \n",
    "Say we have a continuous random variable whose probability density function is given by f(x) = x + 2, when 0 < x â‰¤ 2. We want to find P(0.5 < X < 1). Then we integrate x + 2 within the limits 0.5 and 1. This gives us 1.375. Thus, the probability that the continuous random variable lies between 0.5 and 1 is 1.375."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e721a59-2087-42b0-9c08-93fdcc5543db",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cf587-4d68-4452-bde8-cb12629e6d19",
   "metadata": {},
   "source": [
    "A cumulative distribution function (CDF) describes the probabilities of a random variable having values less than or equal to x. It is a cumulative function because it sums the total likelihood up to that point. Its output always ranges between 0 and 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f460b8c-bba4-444d-a520-45544c5fa143",
   "metadata": {},
   "source": [
    "Let X be the random variable representing the outcome of rolling a fair six-sided die. The CDF for X can be represented as a table or a mathematical function, and it would look like this:\n",
    "\n",
    "   X                      cdf(x)                                                                              \n",
    "   1                        1/6                                                      \n",
    "   2                        2/6                                                                                 \n",
    "   3                        3/6                                                                               \n",
    "   4                        4/6                                                          \n",
    "   5                        5/6                                                              \n",
    "   6                        6/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73176545-74c5-4d05-9b65-be74bc186b6c",
   "metadata": {},
   "source": [
    "The cumulative distribution function (CDF) calculates the cumulative probability for a given x-value. Use the CDF to determine the likelihood that a random observation taken from the population will be less than or equal to a particular value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887368df-d254-483e-9ae1-cd080aec8780",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c47844-be76-4395-bdc5-fb482548dc52",
   "metadata": {},
   "source": [
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is a very common and important distribution in statistics. It is a bell-shaped curve that is symmetrical and has a peak at the mean. The normal distribution can be used to model a wide variety of phenomena, including:                                                     \n",
    "\n",
    "1. Human characteristics: Height, weight, IQ, shoe size, etc.                                      \n",
    "2. Natural phenomena: Temperature, rainfall, wind speed, etc.                                                \n",
    "3. Manufacturing processes: Weight of a product, time to complete a task, etc.                                        \n",
    "4. Financial data: Stock prices, interest rates, etc.                                                      \n",
    "The parameters of the normal distribution are the mean and the standard deviation. The mean is the central point of the distribution, and the standard deviation measures how spread out the distribution is.                                  \n",
    "\n",
    "The mean and standard deviation have a direct impact on the shape of the normal distribution. A higher mean will shift the distribution to the right, and a lower mean will shift it to the left. A higher standard deviation will spread out the distribution, and a lower standard deviation will make it more concentrated.                                      \n",
    "\n",
    "Here are some examples of how the parameters of the normal distribution relate to the shape of the distribution:         \n",
    "\n",
    "1. Mean: If the mean of a normal distribution is 100 and the standard deviation is 10, then the distribution will be centered at 100 and most of the values will be between 90 and 110. However, if the mean is changed to 50, the distribution will be shifted to the left and most of the values will be between 40 and 60.                            \n",
    "2. Standard deviation: If the standard deviation of a normal distribution is 10, then the distribution will be spread out and most of the values will be within 2 standard deviations of the mean (i.e., between 90 and 110). However, if the standard deviation is changed to 5, the distribution will be more concentrated and most of the values will be within 1 standard deviation of the mean (i.e., between 95 and 105).                                                     \n",
    "The normal distribution is a very powerful tool for modeling and analyzing data. By understanding the parameters of the normal distribution, we can gain insights into the underlying processes that generate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27bab9-6523-4a0b-91e6-f9b8baad102e",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef44a2a-3ea7-4a17-b483-aa4d34fb3908",
   "metadata": {},
   "source": [
    "\n",
    "The normal distribution is important because it is the most common distribution in statistics. It is also a very versatile distribution, and can be used to model a wide variety of phenomena.                                        \n",
    "\n",
    "Here are some of the reasons why the normal distribution is important:                                           \n",
    "\n",
    "1. It is a good approximation for many real-world distributions.                                          \n",
    "2. It is easy to understand and use.                                                                    \n",
    "3. There are many statistical tests and procedures that are based on the normal distribution.                        \n",
    "4. It is used in many different fields, including science, engineering, finance, and medicine.                          \n",
    "Here are a few real-life examples of the normal distribution:                               \n",
    "\n",
    "1. Human characteristics: Height, weight, IQ, shoe size, etc.                             \n",
    "2. Natural phenomena: Temperature, rainfall, wind speed, etc.                                    \n",
    "3. Manufacturing processes: Weight of a product, time to complete a task, etc.                                \n",
    "4. Financial data: Stock prices, interest rates, etc.                                                        \n",
    "The normal distribution can be used to answer a variety of questions about real-world data. For example, we can use the normal distribution to:                                                \n",
    "\n",
    "1. Estimate the probability of a certain event happening.                                           \n",
    "2. Compare two different groups of people or things.                                                \n",
    "3. Identify outliers in a dataset.                                                        \n",
    "4. Make predictions about future events.                                                                    \n",
    "Here are a few specific examples of how the normal distribution is used in the real world:                    \n",
    "\n",
    "1. Education: Teachers can use the normal distribution to grade their students' tests and assignments.                \n",
    "2. Medicine: Doctors can use the normal distribution to diagnose diseases and prescribe treatments.                  \n",
    "3. Finance: Investors can use the normal distribution to manage their portfolios and make investment decisions.            \n",
    "4. Quality control: Manufacturers can use the normal distribution to ensure that their products meet quality standards.      \n",
    "The normal distribution is a very important tool for understanding and analyzing the world around us. By understanding the normal distribution, we can make better decisions and solve problems more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5f3c0-1b9e-4dd6-9e5d-80aa72992f1d",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86064038-d634-422a-b44e-ca6586bd0bb7",
   "metadata": {},
   "source": [
    "\n",
    "A Bernoulli distribution is a probability distribution that models the outcome of a single experiment with two possible outcomes. The two outcomes are typically represented by 1 and 0, such as success and failure, heads and tails, or yes and no.\n",
    "\n",
    "The Bernoulli distribution is parameterized by a single parameter, p, which is the probability of success. The probability of failure is then 1âˆ’p.\n",
    "\n",
    "Here is an example of a Bernoulli distribution:\n",
    "\n",
    "Experiment: Flipping a coin\n",
    "Possible outcomes: Heads (success) or tails (failure)\n",
    "Parameter: p = probability of heads\n",
    "The Bernoulli distribution can be used to calculate the probability of any event that has two possible outcomes. For example, we can use the Bernoulli distribution to calculate the probability of getting heads on a coin flip, or the probability of passing an exam.\n",
    "\n",
    "Difference between Bernoulli and Binomial Distributions\n",
    "\n",
    "The binomial distribution is a generalization of the Bernoulli distribution. It models the outcome of multiple independent Bernoulli experiments. The binomial distribution is parameterized by two parameters: n, the number of experiments, and p, the probability of success on each experiment.\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution when n=1. In other words, the Bernoulli distribution models the outcome of a single Bernoulli experiment, while the binomial distribution models the outcome of multiple Bernoulli experiments.\n",
    "\n",
    "Here is an example of a binomial distribution:\n",
    "\n",
    "Experiment: Flipping a coin 10 times\n",
    "Possible outcomes: The number of heads obtained\n",
    "Parameters: n=10, p = probability of heads\n",
    "The binomial distribution can be used to calculate the probability of any event that involves the number of successes in a sequence of independent Bernoulli experiments. For example, we can use the binomial distribution to calculate the probability of getting at least 5 heads in 10 coin flips, or the probability of passing at least 6 exams out of 10.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The Bernoulli and binomial distributions are two important probability distributions that are used to model a variety of real-world phenomena. The Bernoulli distribution models the outcome of a single experiment with two possible outcomes, while the binomial distribution models the outcome of multiple independent Bernoulli experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac99208-a406-49ae-a39f-d212a684c107",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e73b4a-1739-4187-a9a2-80f2a4ed245e",
   "metadata": {},
   "source": [
    "mean = 50                                                       \n",
    "standard deviation = 10                                                          \n",
    "dataset is normally distributed.                                                 \n",
    "first find the z score,    \n",
    "Z = (X - Î¼) / Ïƒ                                                                              \n",
    "here X is the value you want to find the probability for (60 in this case).                              \n",
    "Î¼ is the mean (50 in this case).                                                                  \n",
    "Ïƒ is the standard deviation (10 in this case).                                               \n",
    "Z = (60-50)/10 = 1.                                                     \n",
    "find p(z>1)                                                   \n",
    "By using z table p(z<=1) = 0.8413.                                             \n",
    "p(z>1) = 1- p(z<=1) = 1-0.8413 = 0.1587.                                     \n",
    "So, the probability that a randomly selected observation will be greater than 60 in this dataset is approximately 0.1587 or 15.87%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68355df2-968e-4513-bd2b-6a63981163ff",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703e62b-dea3-4b1e-b077-e73c4b2b0dc0",
   "metadata": {},
   "source": [
    "\n",
    "A uniform distribution, also known as a rectangular distribution, is a probability distribution in statistics where all possible outcomes are equally likely. In other words, in a uniform distribution, every value within a given range has an equal probability of occurring. This distribution is often represented as a flat, horizontal line in a probability density function (PDF) or histogram.                                                 \n",
    "\n",
    "Key characteristics of a uniform distribution:                                                      \n",
    "\n",
    "1. Equal Probability: In a uniform distribution, all values within the defined range have the same probability of occurring. There are no peaks or troughs in the distribution, and it's a straight horizontal line.             \n",
    "\n",
    "2. Defined Range: The distribution is defined within a specific range, denoted by [a, b], where \"a\" represents the minimum value, and \"b\" represents the maximum value. Any value outside this range has a probability of zero.    \n",
    "\n",
    "3. Constant Probability Density: The probability density function (PDF) is a constant value between \"a\" and \"b,\" and it's zero outside this range.                                                                                                 \n",
    "\n",
    "4. Uniformity: Because of its uniformity, it's often used when there's no specific reason to expect one value to be more likely than another within the given range.                                                                                          \n",
    "\n",
    "Example of a Uniform Distribution:                                                                    \n",
    "\n",
    "Let's say you have a six-sided fair die (like a regular game die) with faces numbered from 1 to 6. The probability of rolling any one of the six numbers is 1/6. This is a classic example of a discrete uniform distribution. Each outcome (1, 2, 3, 4, 5, and 6) is equally likely, and the probability for each is the same (1/6).             \n",
    "\n",
    "If you were to represent this using a probability density function (PDF), it would look like this:              \n",
    "\n",
    "P(X = 1) = 1/6                                                                    \n",
    "P(X = 2) = 1/6                                                                             \n",
    "P(X = 3) = 1/6                                                                                \n",
    "P(X = 4) = 1/6                                                                                  \n",
    "P(X = 5) = 1/6                                                                                 \n",
    "P(X = 6) = 1/6                                                                                           \n",
    "In this example, the values 1 through 6 form a uniform distribution because each value has an equal chance of occurring when rolling the die, and this chance is 1/6 for each value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a89cb-8a85-4bd5-936c-255faa1eb027",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89249ea-65c8-424c-afa7-ba6169a9bba2",
   "metadata": {},
   "source": [
    "The Z-score, also known as the standard score or standardized score, is a statistical measure that quantifies how far a data point is from the mean of a dataset in terms of standard deviations. It is used to standardize or normalize data, allowing for comparisons between different datasets with different units and distributions. The Z-score is calculated using the following formula:                                                    \n",
    "\n",
    "\n",
    "Z=  (X - Î¼) / Ïƒ                                                       \n",
    "\n",
    "\n",
    "Where:                                                    \n",
    "\n",
    "ï¿½Z is the Z-score.                                                \n",
    "ï¿½X is the individual data point.                                              \n",
    "ï¿½Î¼ is the mean (average) of the dataset.                                                    \n",
    "ï¿½Ïƒ is the standard deviation of the dataset.                                                        \n",
    "The importance of the Z-score is as follows:                                                    \n",
    "\n",
    "1. Standardization: Z-scores standardize data, making it possible to compare data points from different datasets or variables. It allows for a common scale to assess how far a data point is from the mean in terms of standard deviations.                                                                             \n",
    "\n",
    "2. Identification of Outliers: Z-scores help identify outliers in a dataset. Data points with Z-scores that are significantly different from the mean (i.e., Z-scores with large absolute values) can be considered outliers.        \n",
    "                                                       \n",
    "3. Probability and Normal Distribution: Z-scores are crucial in working with the normal distribution. In a standard normal distribution (with a mean of 0 and a standard deviation of 1), Z-scores directly represent probabilities. You can use Z-scores to find the probability of a data point falling within a specific range or above/below a certain threshold in a normal distribution.                                                  \n",
    "\n",
    "4. Data Analysis and Inference: Z-scores are used in various statistical analyses, including hypothesis testing, quality control, and market research. They help in making data-driven decisions and drawing inferences about the population based on sample data.                                                         \n",
    "\n",
    "5. Standardizing Variables: In multivariate analysis, Z-scores are often used to standardize variables, which is important in techniques like principal component analysis (PCA) and factor analysis. Standardized variables make it easier to understand the relative importance of different variables in a dataset.                          \n",
    "\n",
    "In summary, Z-scores are a fundamental concept in statistics that provide a common framework for comparing and analyzing data. They are particularly valuable when dealing with data that may have different units or distributions, allowing for meaningful comparisons and statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb778f-284c-4372-a3ff-ef276ea12341",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b64ce-581d-4b00-ad0d-b7fcb3d7ab44",
   "metadata": {},
   "source": [
    "The central limit theorem says that the sampling distribution of the mean will always be normally distributed, as long as the sample size is large enough. Regardless of whether the population has a normal, Poisson, binomial, or any other distribution, the sampling distribution of the mean will be normal.                                                                                                                                                           \n",
    "The central limit theorem is useful when analyzing large data sets because it allows one to assume that the sampling distribution of the mean will be normally-distributed in most cases. This allows for easier statistical analysis and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a299d-9699-4cc6-bb78-c098767197c4",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa95cf5b-bb9e-4f6e-a399-221fb15d57fd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
